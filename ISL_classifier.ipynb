{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bApTJYeOgP6h",
    "outputId": "7fc9db3f-f573-4576-ae8e-8b333fb7e7f7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\tfod_env\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JIOzYKNkOh1t"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4on_iLLLO87q"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('keypoints.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QfkE0RZmguGd"
   },
   "outputs": [],
   "source": [
    "data[0] = data[0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyrM0MDTPiGl",
    "outputId": "7189ea03-20f9-4519-d555-84d46e4f2794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "OC5TcyT9U63v",
    "outputId": "a07aab43-c24a-40da-a50e-eef9f04f4f4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>-0.613333</td>\n",
       "      <td>-0.306667</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.520000</td>\n",
       "      <td>-0.920000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-0.560000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>-0.613333</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>-0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.628571</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>-0.685714</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>-0.514286</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>-0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>-0.013514</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>-0.148649</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-0.283784</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>-0.391892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>-0.945946</td>\n",
       "      <td>-0.081081</td>\n",
       "      <td>-0.527027</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>-0.716216</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>-0.864865</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>-0.013699</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>-0.205479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>-0.493151</td>\n",
       "      <td>-0.068493</td>\n",
       "      <td>-0.767123</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>-0.917808</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>-0.698630</td>\n",
       "      <td>-0.041096</td>\n",
       "      <td>-0.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>-0.070423</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>-0.211268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.352113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>-0.478873</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>-0.816901</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>-0.901408</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>-0.661972</td>\n",
       "      <td>-0.070423</td>\n",
       "      <td>-0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22367</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168605</td>\n",
       "      <td>-0.029070</td>\n",
       "      <td>-0.354651</td>\n",
       "      <td>-0.186047</td>\n",
       "      <td>-0.436047</td>\n",
       "      <td>-0.360465</td>\n",
       "      <td>-0.343023</td>\n",
       "      <td>-0.430233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087209</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>-0.465116</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>-0.633721</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>-0.744186</td>\n",
       "      <td>0.133721</td>\n",
       "      <td>-0.848837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22368</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>-0.023669</td>\n",
       "      <td>-0.355030</td>\n",
       "      <td>-0.177515</td>\n",
       "      <td>-0.431953</td>\n",
       "      <td>-0.355030</td>\n",
       "      <td>-0.343195</td>\n",
       "      <td>-0.426036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071006</td>\n",
       "      <td>-0.994083</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>-0.455621</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>-0.627219</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>-0.739645</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>-0.840237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.170588</td>\n",
       "      <td>-0.023529</td>\n",
       "      <td>-0.352941</td>\n",
       "      <td>-0.188235</td>\n",
       "      <td>-0.417647</td>\n",
       "      <td>-0.364706</td>\n",
       "      <td>-0.317647</td>\n",
       "      <td>-0.435294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070588</td>\n",
       "      <td>-0.994118</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>-0.464706</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.635294</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>-0.741176</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>-0.847059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.170588</td>\n",
       "      <td>-0.023529</td>\n",
       "      <td>-0.347059</td>\n",
       "      <td>-0.182353</td>\n",
       "      <td>-0.423529</td>\n",
       "      <td>-0.358824</td>\n",
       "      <td>-0.329412</td>\n",
       "      <td>-0.429412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076471</td>\n",
       "      <td>-0.994118</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>-0.458824</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>-0.629412</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>-0.741176</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>-0.847059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>-0.023669</td>\n",
       "      <td>-0.355030</td>\n",
       "      <td>-0.183432</td>\n",
       "      <td>-0.426036</td>\n",
       "      <td>-0.355030</td>\n",
       "      <td>-0.331361</td>\n",
       "      <td>-0.426036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071006</td>\n",
       "      <td>-0.994083</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>-0.455621</td>\n",
       "      <td>0.094675</td>\n",
       "      <td>-0.627219</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>-0.739645</td>\n",
       "      <td>0.147929</td>\n",
       "      <td>-0.840237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22372 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1    2         3         4         5         6         7         8   \\\n",
       "0      0.0  0.0 -0.333333 -0.120000 -0.613333 -0.306667 -0.800000 -0.520000   \n",
       "1      0.0  0.0  0.285714  0.057143  0.571429 -0.085714  0.800000 -0.214286   \n",
       "2      0.0  0.0  0.270270 -0.013514  0.513514 -0.148649  0.702703 -0.283784   \n",
       "3      0.0  0.0  0.301370  0.109589  0.671233 -0.013699  0.876712 -0.205479   \n",
       "4      0.0  0.0  0.281690  0.056338  0.647887 -0.070423  0.873239 -0.211268   \n",
       "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "22367  0.0  0.0 -0.168605 -0.029070 -0.354651 -0.186047 -0.436047 -0.360465   \n",
       "22368  0.0  0.0 -0.171598 -0.023669 -0.355030 -0.177515 -0.431953 -0.355030   \n",
       "22369  0.0  0.0 -0.170588 -0.023529 -0.352941 -0.188235 -0.417647 -0.364706   \n",
       "22370  0.0  0.0 -0.170588 -0.023529 -0.347059 -0.182353 -0.423529 -0.358824   \n",
       "22371  0.0  0.0 -0.171598 -0.023669 -0.355030 -0.183432 -0.426036 -0.355030   \n",
       "\n",
       "             9         10  ...        33        34        35        36  \\\n",
       "0     -0.920000 -0.666667  ...  0.080000 -0.560000  0.293333 -0.640000   \n",
       "1      1.000000 -0.300000  ...  0.314286 -0.285714  0.200000 -0.628571   \n",
       "2      0.851351 -0.391892  ...  0.378378 -0.945946 -0.081081 -0.527027   \n",
       "3      1.000000 -0.369863  ...  0.150685 -0.493151 -0.068493 -0.767123   \n",
       "4      1.000000 -0.352113  ...  0.126761 -0.478873 -0.098592 -0.816901   \n",
       "...         ...       ...  ...       ...       ...       ...       ...   \n",
       "22367 -0.343023 -0.430233  ... -0.087209 -1.000000  0.034884 -0.465116   \n",
       "22368 -0.343195 -0.426036  ... -0.071006 -0.994083  0.035503 -0.455621   \n",
       "22369 -0.317647 -0.435294  ... -0.070588 -0.994118  0.047059 -0.464706   \n",
       "22370 -0.329412 -0.429412  ... -0.076471 -0.994118  0.041176 -0.458824   \n",
       "22371 -0.331361 -0.426036  ... -0.071006 -0.994083  0.041420 -0.455621   \n",
       "\n",
       "             37        38        39        40        41        42  \n",
       "0      0.373333 -0.800000  0.306667 -0.613333  0.226667 -0.533333  \n",
       "1      0.442857 -0.685714  0.385714 -0.514286  0.257143 -0.442857  \n",
       "2     -0.027027 -0.716216  0.027027 -0.864865  0.054054 -1.000000  \n",
       "3      0.054795 -0.917808  0.013699 -0.698630 -0.041096 -0.602740  \n",
       "4      0.028169 -0.901408 -0.014085 -0.661972 -0.070423 -0.591549  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "22367  0.081395 -0.633721  0.116279 -0.744186  0.133721 -0.848837  \n",
       "22368  0.088757 -0.627219  0.124260 -0.739645  0.153846 -0.840237  \n",
       "22369  0.100000 -0.635294  0.129412 -0.741176  0.152941 -0.847059  \n",
       "22370  0.094118 -0.629412  0.129412 -0.741176  0.152941 -0.847059  \n",
       "22371  0.094675 -0.627219  0.124260 -0.739645  0.147929 -0.840237  \n",
       "\n",
       "[22372 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]  \n",
    "X# Features (keypoints)\n",
    "# y = data[0]           # Labels (A-Z, 1-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C6Fev9pFNPA4"
   },
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GptfpfFZQ859",
    "outputId": "d8dcef55-f4b7-4b8b-adfb-2066770dd343"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tfod_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, ..., 8, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = enc.fit_transform(data[[0]])\n",
    "y\n",
    "# y_encoded = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Save the label encoder to use during detection\n",
    "# with open('label_map.pkl', 'wb') as f:\n",
    "#     pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXeK_Oh3lSGo",
    "outputId": "fd14d294-df98-4171-e4e1-da13d0c98ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9 9 ... 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-725RwgrSiLh"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MoP6X2dFXtaq"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fwYKKiYKUDMp"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(1470, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(832, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(428, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(264, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(35, activation='softmax')  # 35 classes\n",
    "])\n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Dense(1470, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(832, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(428, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(264, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(len(label_encoder.classes_), activation='softmax')  # num of classes\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RZKhTkEfYd6i"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLfTS486YqiG",
    "outputId": "4465dc13-0e94-4a54-d1b5-bb4c84e82635",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "112/112 [==============================] - 5s 27ms/step - loss: 2.6391 - accuracy: 0.2343 - val_loss: 1.2368 - val_accuracy: 0.6433\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 1.2672 - accuracy: 0.5817 - val_loss: 0.6347 - val_accuracy: 0.7872\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.8384 - accuracy: 0.7156 - val_loss: 0.4849 - val_accuracy: 0.8257\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 3s 26ms/step - loss: 0.6810 - accuracy: 0.7624 - val_loss: 0.4125 - val_accuracy: 0.8494\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.5854 - accuracy: 0.7926 - val_loss: 0.3844 - val_accuracy: 0.8651\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.5338 - accuracy: 0.8134 - val_loss: 0.3381 - val_accuracy: 0.8852\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4969 - accuracy: 0.8265 - val_loss: 0.3218 - val_accuracy: 0.8827\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4515 - accuracy: 0.8405 - val_loss: 0.3160 - val_accuracy: 0.8911\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.4334 - accuracy: 0.8467 - val_loss: 0.3060 - val_accuracy: 0.8860\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 3s 28ms/step - loss: 0.4152 - accuracy: 0.8530 - val_loss: 0.2787 - val_accuracy: 0.8919\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.3947 - accuracy: 0.8599 - val_loss: 0.2716 - val_accuracy: 0.9017\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.3795 - accuracy: 0.8653 - val_loss: 0.2575 - val_accuracy: 0.9126\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.3682 - accuracy: 0.8683 - val_loss: 0.2435 - val_accuracy: 0.9198\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.3504 - accuracy: 0.8712 - val_loss: 0.2443 - val_accuracy: 0.9165\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.3473 - accuracy: 0.8753 - val_loss: 0.2489 - val_accuracy: 0.9137\n",
      "Epoch 15: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x234eaf0c2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.2, callbacks=[es])\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', patience=2, verbose=1)\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.2, callbacks=[es])\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.2, callbacks=[es])\n",
    "# model.fit(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APJrH5DCZPVz",
    "outputId": "e76defc1-3779-4590-ffc8-b2de65864047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26303303241729736, 0.9059218168258667]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMScXAuychzn",
    "outputId": "421238f9-dbfb-4be5-bad7-da5fdbf9dce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s 5ms/step\n",
      "Accuracy: 0.9059217877094972\n",
      "Precision: 0.917003380909106\n",
      "Recall: 0.9109071118169193\n",
      "F1-score: 0.9094414474823717\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the validation set and compute performance metrics\n",
    "y_val_pred = model.predict(X_test)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "acc = accuracy_score(y_test, y_val_pred_classes)\n",
    "prec = precision_score(y_test, y_val_pred_classes, average='macro')\n",
    "rec = recall_score(y_test, y_val_pred_classes, average='macro')\n",
    "f1 = f1_score(y_test, y_val_pred_classes, average='macro')\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yphwMRARaZVL"
   },
   "outputs": [],
   "source": [
    "# model.save(\"model.h5\")\n",
    "model.save(\"sign_language_model.keras\")  # Saves a folder with model files\n",
    "# model.save('my_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model(\"sign_language_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
